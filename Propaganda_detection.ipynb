{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pudBhrGgX-3u",
        "outputId": "3af368b2-237b-4678-80c9-fc437aeaae25"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive/; to attempt to forcibly remount, call drive.mount(\"/content/drive/\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive/\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "UzZD7qAvdZ6k"
      },
      "outputs": [],
      "source": [
        "##!rm -rf /content/drive/MyDrive/propaganda_dataset_v2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "44B9xQepX_qi"
      },
      "outputs": [],
      "source": [
        "train_path='/content/drive/MyDrive/propaganda_dataset_v2/propaganda_train.tsv'\n",
        "valid_path='/content/drive/MyDrive/propaganda_dataset_v2/propaganda_val.tsv'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kd6hiNmOYxPf",
        "outputId": "563380c5-b46e-4899-c9b2-6ff70d73dccd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Thu Mar 23 01:08:28 2023       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 525.85.12    Driver Version: 525.85.12    CUDA Version: 12.0     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   63C    P0    30W /  70W |      0MiB / 15360MiB |      5%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YfcYxZz7Y4FV",
        "outputId": "ccccf0bc-fd7d-4d8e-fc32-baee43063d7e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting transformers\n",
            "  Downloading transformers-4.27.2-py3-none-any.whl (6.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.8/6.8 MB\u001b[0m \u001b[31m40.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting tokenizers!=0.11.3,<0.14,>=0.11.1\n",
            "  Downloading tokenizers-0.13.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.6/7.6 MB\u001b[0m \u001b[31m81.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting huggingface-hub<1.0,>=0.11.0\n",
            "  Downloading huggingface_hub-0.13.3-py3-none-any.whl (199 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m199.8/199.8 KB\u001b[0m \u001b[31m25.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.9/dist-packages (from transformers) (23.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.9/dist-packages (from transformers) (2.27.1)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.9/dist-packages (from transformers) (4.65.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.9/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.9/dist-packages (from transformers) (1.22.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.9/dist-packages (from transformers) (3.10.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.9/dist-packages (from transformers) (2022.10.31)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.9/dist-packages (from huggingface-hub<1.0,>=0.11.0->transformers) (4.5.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (2022.12.7)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (3.4)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (2.0.12)\n",
            "Installing collected packages: tokenizers, huggingface-hub, transformers\n",
            "Successfully installed huggingface-hub-0.13.3 tokenizers-0.13.2 transformers-4.27.2\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "Abn5gGk8Y6LW"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import shutil\n",
        "import sys   \n",
        "     "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "t65ZqrRnY8_M"
      },
      "outputs": [],
      "source": [
        "\n",
        "training_df = pd.read_table(train_path)\n",
        "valid_df = pd.read_table(valid_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "yrubNKJXY_1Y",
        "outputId": "9e29d9e5-2510-44cb-b625-4aac04ad1b33"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "            label                                  tagged_in_context\n",
              "0  not_propaganda         No, <BOS> he <EOS> will not be confirmed. \n",
              "1  not_propaganda  This declassification effort <BOS> won’t make ...\n",
              "2     flag_waving  The Obama administration misled the <BOS> Amer...\n",
              "3  not_propaganda  “It looks like we’re capturing the demise of t...\n",
              "4  not_propaganda           <BOS> Location: Westerville, Ohio <EOS> "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-d964a376-80dd-4d7d-8a6f-1230f360d523\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>label</th>\n",
              "      <th>tagged_in_context</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>not_propaganda</td>\n",
              "      <td>No, &lt;BOS&gt; he &lt;EOS&gt; will not be confirmed.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>not_propaganda</td>\n",
              "      <td>This declassification effort &lt;BOS&gt; won’t make ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>flag_waving</td>\n",
              "      <td>The Obama administration misled the &lt;BOS&gt; Amer...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>not_propaganda</td>\n",
              "      <td>“It looks like we’re capturing the demise of t...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>not_propaganda</td>\n",
              "      <td>&lt;BOS&gt; Location: Westerville, Ohio &lt;EOS&gt;</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d964a376-80dd-4d7d-8a6f-1230f360d523')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-d964a376-80dd-4d7d-8a6f-1230f360d523 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-d964a376-80dd-4d7d-8a6f-1230f360d523');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ],
      "source": [
        "training_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d7xCmZszZCAW",
        "outputId": "3ed100c3-b960-4386-c8f6-93b3f05cf8d0"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'appeal_to_fear_prejudice': 0,\n",
              " 'causal_oversimplification': 1,\n",
              " 'doubt': 2,\n",
              " 'exaggeration,minimisation': 3,\n",
              " 'flag_waving': 4,\n",
              " 'loaded_language': 5,\n",
              " 'name_calling,labeling': 6,\n",
              " 'not_propaganda': 7,\n",
              " 'repetition': 8}"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ],
      "source": [
        "labellist=sorted(list(set(training_df['label'].unique()).union(set(valid_df['label'].unique())))) \n",
        "\n",
        "labels={label:i for i,label in enumerate(labellist)}\n",
        "labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 545
        },
        "id": "JiQsq5lgh0oS",
        "outputId": "edc76613-c3f9-4ed8-fcfd-f8e79a8116b6"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0, 0.5, 'Count')"
            ]
          },
          "metadata": {},
          "execution_count": 19
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 576x432 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.figure(figsize=(8,6))\n",
        "training_df['label'].value_counts().sort_values(ascending=False).plot(kind='bar', \n",
        "                                                                title='Number of label')\n",
        "plt.xlabel('Label names')\n",
        "plt.ylabel('Count')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "YEDW-RdiZOBL"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "from transformers import BertTokenizer,BertModel, BertForMaskedLM\n",
        "tokenizer=BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "\n",
        "class Dataset(torch.utils.data.Dataset):\n",
        "    \n",
        "    def __init__(self,df,column='tagged_in_context'):\n",
        "        self.labels=[labels[label] for label in df['label']]\n",
        "        self.texts=[tokenizer(text.lower(),padding='max_length',max_length=512,truncation=True,return_tensors=\"pt\") for text in df[column]]\n",
        "        \n",
        "    def classes(self):\n",
        "        return self.labels\n",
        "    \n",
        "    def __len__(self):\n",
        "        return len(self.labels)\n",
        "    \n",
        "    def get_batch_labels(self,idx):\n",
        "        return np.array(self.labels[idx])\n",
        "    \n",
        "    def get_batch_texts(self,idx):\n",
        "        return self.texts[idx]\n",
        "    \n",
        "    def __getitem__(self,idx):\n",
        "        batch_texts=self.get_batch_texts(idx)\n",
        "        batch_y=self.get_batch_labels(idx)\n",
        "        \n",
        "        return batch_texts,batch_y\n",
        "    \n",
        "\n",
        "train_data=Dataset(training_df)\n",
        "test_data=Dataset(valid_df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VUqj5A6WZrS_",
        "outputId": "ce1471ed-5c32-4233-eaac-63d66d20d0ad"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GPU acceleration enabled\n"
          ]
        }
      ],
      "source": [
        "use_cuda=torch.cuda.is_available()\n",
        "if use_cuda:\n",
        "  print(\"GPU acceleration enabled\")\n",
        "else:\n",
        "  print(\"GPU acceleration NOT enabled.  If using Colab, have you changed the runtype type and selected GPU as the hardware accelerator?\")\n",
        "device=torch.device(\"cuda\" if use_cuda else \"cpu\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "6VXNFnpHaF6p"
      },
      "outputs": [],
      "source": [
        "def prepare_inputs(input1,label,device):\n",
        "  label=label.to(device)\n",
        "  mask=input1['attention_mask'].to(device)\n",
        "  input_id=input1['input_ids'].squeeze(1).to(device)\n",
        "  return (input_id,mask,label)\n",
        "  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 260,
          "referenced_widgets": [
            "a5f60b7a3780459e99a534165d22e238",
            "2c03c7e3033446e6abdaa13e323db90a",
            "a00813853f2b4fd694ddcd1a5c15d2d9",
            "0b7f93d42d8e4fccb16ccb5a98273889",
            "b0c0e216f1eb4ee7b9cb5c146bf9d607",
            "45aeacf98e1940239a5356df3b9007f3",
            "f6aa4af6698c46a2b605fcee01f448c6",
            "d3de20112936440cac0d14afa114073a",
            "7a47570bf38642b38883684635705413",
            "5301181a22a640258bf85d09403006de",
            "5b019e459ad046dc881c8032ff2a8f04"
          ]
        },
        "id": "7T96hEButF_v",
        "outputId": "3f92b54f-9255-42e2-a479-8e44ce178ca8"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading pytorch_model.bin:   0%|          | 0.00/440M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a5f60b7a3780459e99a534165d22e238"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.seq_relationship.bias']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[ 101, 2023, 2003,  ...,    0,    0,    0],\n",
            "        [ 101, 2021, 1051,  ...,    0,    0,    0]], device='cuda:0') tensor([[[1, 1, 1,  ..., 0, 0, 0]],\n",
            "\n",
            "        [[1, 1, 1,  ..., 0, 0, 0]]], device='cuda:0') tensor([1, 2], device='cuda:0')\n",
            "2\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-0.6473, -0.4646, -0.9533,  ..., -0.8127, -0.5241,  0.5567],\n",
              "        [-0.6902, -0.3789, -0.7180,  ..., -0.5118, -0.5204,  0.4499]],\n",
              "       device='cuda:0', grad_fn=<TanhBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ],
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "train_dataloader = torch.utils.data.DataLoader(train_data, batch_size=2, shuffle=True)\n",
        "bert = BertModel.from_pretrained('bert-base-uncased').to(device)\n",
        "\n",
        "for train_input, train_label in train_dataloader:\n",
        "    input_id, mask, label = prepare_inputs(train_input, train_label, device)\n",
        "    input_id = input_id.to(device)\n",
        "    mask = mask.to(device)\n",
        "    label = label.to(device)\n",
        "    output = bert(input_ids=input_id, attention_mask=mask, return_dict=False)\n",
        "    break\n",
        "\n",
        "print(input_id, mask, label)\n",
        "print(len(output))\n",
        "output[1]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "FVj4LEGy7Cne"
      },
      "outputs": [],
      "source": [
        "from torch import nn\n",
        "from transformers import BertModel\n",
        "\n",
        "class BertClassifier(nn.Module):\n",
        "    \n",
        "    def __init__(self, dropout=0.5, num_classes=2, hidden_size=768, num_layers=12, learning_rate=2e-5, batch_size=32, num_epochs=10):\n",
        "        \n",
        "        super(BertClassifier, self).__init__()\n",
        "        \n",
        "        self.bert = BertModel.from_pretrained('bert-base-uncased', hidden_size=hidden_size, num_hidden_layers=num_layers)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        self.linear = nn.Linear(hidden_size, num_classes)\n",
        "        self.relu = nn.ReLU()\n",
        "        \n",
        "        self.learning_rate = learning_rate\n",
        "        self.batch_size = batch_size\n",
        "        self.num_epochs = num_epochs\n",
        "    \n",
        "    def forward(self, input_id, mask):\n",
        "        \n",
        "        last_hidden_layer, pooled_output = self.bert(input_ids=input_id, attention_mask=mask, return_dict=False)\n",
        "        dropout_output = self.dropout(pooled_output)\n",
        "        linear_output = self.linear(dropout_output)\n",
        "        final_layer = self.relu(linear_output)\n",
        "        \n",
        "        return final_layer\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "LyvjwNBDaZl5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        },
        "outputId": "9fd04d69-7a32-41f7-816e-0c14737ec21f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"from torch import nn\\nclass BertClassifier(nn.Module):\\n    \\n    def __init__(self,dropout=0.5,num_classes=2):\\n        \\n        super(BertClassifier,self).__init__()\\n        \\n        self.bert=BertModel.from_pretrained('bert-base-uncased')\\n        self.dropout=nn.Dropout(dropout)\\n        self.linear=nn.Linear(768,num_classes)\\n        self.relu=nn.ReLU()\\n        \\n    def forward(self,input_id,mask):\\n        \\n        last_hidden_layer,pooled_output = self.bert(input_ids=input_id,attention_mask=mask,return_dict=False)\\n        dropout_output=self.dropout(pooled_output)\\n        linear_output=self.linear(dropout_output)\\n        final_layer=self.relu(linear_output)\\n        \\n        return final_layer\\n        \""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "source": [
        "\"\"\"from torch import nn\n",
        "class BertClassifier(nn.Module):\n",
        "    \n",
        "    def __init__(self,dropout=0.5,num_classes=2):\n",
        "        \n",
        "        super(BertClassifier,self).__init__()\n",
        "        \n",
        "        self.bert=BertModel.from_pretrained('bert-base-uncased')\n",
        "        self.dropout=nn.Dropout(dropout)\n",
        "        self.linear=nn.Linear(768,num_classes)\n",
        "        self.relu=nn.ReLU()\n",
        "        \n",
        "    def forward(self,input_id,mask):\n",
        "        \n",
        "        last_hidden_layer,pooled_output = self.bert(input_ids=input_id,attention_mask=mask,return_dict=False)\n",
        "        dropout_output=self.dropout(pooled_output)\n",
        "        linear_output=self.linear(dropout_output)\n",
        "        final_layer=self.relu(linear_output)\n",
        "        \n",
        "        return final_layer\n",
        "        \"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "A4C2UlnWbCfJ"
      },
      "outputs": [],
      "source": [
        "#we now need a training loop\n",
        "\n",
        "from torch.optim import Adam\n",
        "from tqdm import tqdm\n",
        "\n",
        "\n",
        "\n",
        "def train(model, train_data,val_data,learning_rate,epochs):\n",
        "    \n",
        "    train_dataloader=torch.utils.data.DataLoader(train_data,batch_size=2,shuffle=True)\n",
        "    val_dataloader=torch.utils.data.DataLoader(test_data,batch_size=2)\n",
        "    \n",
        "    use_cuda=torch.cuda.is_available()\n",
        "    device=torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
        "    \n",
        "    criterion=nn.CrossEntropyLoss()\n",
        "    optimizer=Adam(model.parameters(),lr=learning_rate)\n",
        "    \n",
        "    if use_cuda:\n",
        "        model=model.cuda()\n",
        "        criterion=criterion.cuda()\n",
        "        \n",
        "    for epoch_num in range(epochs):\n",
        "        total_acc_train=0\n",
        "        total_loss_train=0\n",
        "        model.train()\n",
        "        for train_input,train_label in tqdm(train_dataloader):\n",
        "            \n",
        "            input_id,mask, train_label=prepare_inputs(train_input,train_label,device)\n",
        "            \n",
        "            output=model(input_id,mask)\n",
        "            \n",
        "            batch_loss=criterion(output,train_label.long())\n",
        "            total_loss_train +=batch_loss.item()\n",
        "            \n",
        "            acc=(output.argmax(dim=1)==train_label).sum().item()\n",
        "            total_acc_train+=acc\n",
        "            \n",
        "            model.zero_grad()\n",
        "            batch_loss.backward()\n",
        "            optimizer.step()\n",
        "            \n",
        "        total_acc_val=0\n",
        "        total_loss_val=0  \n",
        "        model.eval()\n",
        "        with torch.no_grad():\n",
        "            for val_input,val_label in val_dataloader:\n",
        "                \n",
        "                input_id,mask, val_label=prepare_inputs(val_input,val_label,device)\n",
        "                \n",
        "                output=model(input_id,mask)\n",
        "                \n",
        "                batch_loss=criterion(output,val_label.long())\n",
        "                \n",
        "                total_loss_val+=batch_loss.item()\n",
        "                \n",
        "                acc=(output.argmax(dim=1)==val_label).sum().item()\n",
        "                total_acc_val+=acc\n",
        "                \n",
        "        print(f'Epochs: {epoch_num+1} | Train Loss: {total_loss_train / len(train_data):.3f} | Train Accuracy: {total_acc_train/len(train_data):.3f}')\n",
        "        print(f'Val loss: {total_loss_val/len(val_data):.3f} | Val Accuracy: {total_acc_val / len(val_data):.3f}')\n",
        "        "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qeOF4cTCbFEJ",
        "outputId": "2e38d15c-1345-4ee8-f738-35829a9c2224"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.seq_relationship.bias']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        }
      ],
      "source": [
        "EPOCHS=2\n",
        "model=BertClassifier(num_classes=len(labels.keys()))\n",
        "LR=1e-6\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6BT6I5DYbGuM",
        "outputId": "9ff10f87-79ba-4bfc-ec92-0ee1022336ed"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1207/1207 [04:21<00:00,  4.62it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 1 | Train Loss: 0.930 | Train Accuracy: 0.466\n",
            "Val loss: 0.837 | Val Accuracy: 0.519\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1207/1207 [04:23<00:00,  4.59it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 2 | Train Loss: 0.841 | Train Accuracy: 0.493\n",
            "Val loss: 0.747 | Val Accuracy: 0.519\n"
          ]
        }
      ],
      "source": [
        "train(model,train_data,test_data,LR,EPOCHS)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "ZUpY9vo9bJPA"
      },
      "outputs": [],
      "source": [
        "output_dir=\"bert-base-uncased-bookclassifier\"\n",
        "torch.save(model,output_dir)\n",
        "input_dir=\"bert-base-uncased-bookclassifier\"\n",
        "complete_model=torch.load(input_dir)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "zVsvKm41vt-H"
      },
      "outputs": [],
      "source": [
        "batchsize=2\n",
        "def evaluate(model,test_dataset):\n",
        "    model.eval()\n",
        "    test_dataloader=torch.utils.data.DataLoader(test_dataset,batch_size=batchsize)\n",
        "    \n",
        "    use_cuda=torch.cuda.is_available()\n",
        "    device=torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
        "    \n",
        "    if use_cuda:\n",
        "        model=model.cuda()\n",
        "        \n",
        "    total_acc_test=0\n",
        "    with torch.no_grad():\n",
        "        count=0\n",
        "        predictions=[]\n",
        "        for test_input,test_label in tqdm(test_dataloader):\n",
        "            count+=batchsize\n",
        "            test_label=test_label.to(device)\n",
        "            mask=test_input['attention_mask'].to(device)\n",
        "            input_id=test_input['input_ids'].squeeze(1).to(device)\n",
        "            output=model(input_id,mask)\n",
        "            #print(output.argmax(dim=1),test_label)\n",
        "            predictions.append(output.argmax(dim=1))  #save the prediction for further analysis\n",
        "            acc=(output.argmax(dim=1)==test_label).sum().item()\n",
        "            \n",
        "            total_acc_test+=acc\n",
        "            if count%100==0:\n",
        "                print(f'Accuracy so far = {total_acc_test/count: .3f}')\n",
        "            \n",
        "    print(f'Test accuracy: {total_acc_test/len(test_dataset): .3f}')\n",
        "    return predictions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "TgCkYtzavwaJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0ef3c1a1-bbd4-4c73-effb-c41f0ce5b611"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 18%|█▊        | 52/290 [00:03<00:15, 14.88it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy so far =  0.500\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 35%|███▌      | 102/290 [00:06<00:13, 14.41it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy so far =  0.510\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 52%|█████▏    | 152/290 [00:10<00:09, 14.59it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy so far =  0.527\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 70%|██████▉   | 202/290 [00:13<00:06, 14.55it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy so far =  0.517\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 87%|████████▋ | 252/290 [00:17<00:02, 14.36it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy so far =  0.516\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 290/290 [00:19<00:00, 14.56it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test accuracy:  0.519\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "predictions=evaluate(model, test_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "Nrs5HHuxwEbv"
      },
      "outputs": [],
      "source": [
        "reverse_index={value:key for (key,value)in labels.items()}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vtoLGiTvvylx"
      },
      "outputs": [],
      "source": [
        "flattened=[]\n",
        "for batch in predictions:\n",
        "    for pred in batch:\n",
        "        flattened.append(reverse_index[pred.item()])\n",
        "valid_df['prediction']=flattened\n",
        "valid_df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9lYdZBrIMMVp"
      },
      "source": [
        "LSTM model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "xoRrkJJRV6bv"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.layers import Embedding\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.preprocessing.text import one_hot\n",
        "from tensorflow.keras.layers import LSTM\n",
        "from tensorflow.keras.layers import Dense\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.utils import to_categorical\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.layers import Bidirectional\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7MSo4HLdb7Cj",
        "outputId": "778b138f-ef50-455c-8662-f4b98928e6e0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(2414,)\n",
            "(2414,)\n"
          ]
        }
      ],
      "source": [
        "y=training_df['label']\n",
        "X=training_df['tagged_in_context']\n",
        "print(X.shape)\n",
        "print(y.shape)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "z9Tq6R6rI09m"
      },
      "outputs": [],
      "source": [
        "tokenizer=Tokenizer()\n",
        "tokenizer.fit_on_texts(X)\n",
        "sequences = tokenizer.texts_to_sequences(X)\n",
        "max_len=100  #padding\n",
        "X = pad_sequences(sequences, maxlen=max_len, padding='post', truncating='post')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lEkZFFJuvUlQ",
        "outputId": "27ef2a03-f428-4df5-b345-ec2f976a7d94"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(580, 100)\n",
            "(580,)\n"
          ]
        }
      ],
      "source": [
        "#Validation data\n",
        "X_val=valid_df['tagged_in_context']\n",
        "tokenizer=Tokenizer()\n",
        "tokenizer.fit_on_texts(X_val)\n",
        "sequences = tokenizer.texts_to_sequences(X_val)\n",
        "max_len=100  #padding\n",
        "X_val= pad_sequences(sequences, maxlen=max_len, padding='post', truncating='post')\n",
        "y_val=valid_df['label']\n",
        "print(X_val.shape)\n",
        "print(y_val.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "3ewjbd4YN1nZ"
      },
      "outputs": [],
      "source": [
        "from keras.utils import to_categorical\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "# encode labels as integers\n",
        "label_encoder = LabelEncoder()\n",
        "y = label_encoder.fit_transform(y)\n",
        "y_val = label_encoder.transform(y_val)\n",
        "\n",
        "# convert labels to one-hot encoding\n",
        "y = to_categorical(y, num_classes=9)\n",
        "y_val = to_categorical(y_val, num_classes=9)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "PJEMnk3wszM9"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train,X_test,y_train,y_test =train_test_split(X, y, test_size=0.30, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "mLmv0RsedbKK"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hm0xV0vlJbwt",
        "outputId": "082ca7cf-7bc8-45e5-a08b-492eac16afb9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1689, 100)\n",
            "(1689, 9)\n"
          ]
        }
      ],
      "source": [
        "print(X_train.shape)\n",
        "print(y_train.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ChGQ6ivMH1nU",
        "outputId": "21982de7-2643-4c8e-f993-c1705feac02f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(725, 9)\n",
            "(725, 100)\n"
          ]
        }
      ],
      "source": [
        "print(y_test.shape)\n",
        "print(X_test.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "3U7F_MLaTfFU"
      },
      "outputs": [],
      "source": [
        "embedding_feature=len(tokenizer.word_index)\n",
        "embedding_feature\n",
        "max_features = 10000  # Number of words in the vocabulary\n",
        "embedding_dim = 128  # Dimension of the word embeddings\n",
        "lstm_units = 128  # Number of LSTM units\n",
        "batch_size = 64\n",
        "epochs = 10\n",
        "num_labels = 9"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        },
        "id": "lN4pwHDMXjR2",
        "outputId": "768abe85-2e0e-458a-b779-7cf687c0fa72"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"\\nmax_features = 10000  # Number of words in the vocabulary\\nembedding_dim = 128  # Dimension of the word embeddings\\nlstm_units = 128  # Number of LSTM units\\nbatch_size = 64\\nepochs = 10\\nnum_labels = 9\\n\\n# Define the model architecture\\nmodel = Sequential()\\nmodel.add(tf.keras.layers.Embedding(max_features, embedding_dim, input_length=max_len))\\nmodel.add(Bidirectional(LSTM(lstm_units, dropout=0.2, recurrent_dropout=0.2)))\\nmodel.add(Dense(num_labels, activation='softmax'))\\n\\n# Compile the model\\noptimizer = Adam(learning_rate=0.001)\\nmodel.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])\\n\\n# Print the model summary\\nmodel.summary()\\n\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 31
        }
      ],
      "source": [
        "'''\n",
        "max_features = 10000  # Number of words in the vocabulary\n",
        "embedding_dim = 128  # Dimension of the word embeddings\n",
        "lstm_units = 128  # Number of LSTM units\n",
        "batch_size = 64\n",
        "epochs = 10\n",
        "num_labels = 9\n",
        "\n",
        "# Define the model architecture\n",
        "model = Sequential()\n",
        "model.add(tf.keras.layers.Embedding(max_features, embedding_dim, input_length=max_len))\n",
        "model.add(Bidirectional(LSTM(lstm_units, dropout=0.2, recurrent_dropout=0.2)))\n",
        "model.add(Dense(num_labels, activation='softmax'))\n",
        "\n",
        "# Compile the model\n",
        "optimizer = Adam(learning_rate=0.001)\n",
        "model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
        "\n",
        "# Print the model summary\n",
        "model.summary()\n",
        "'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NkLnz1_pan2o",
        "outputId": "5d12d4f1-e988-4ae2-bf1c-9681c7778569"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Layer lstm_1 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm_1 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm_1 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 1\n",
            "Epoch 1/10\n",
            "22/22 [==============================] - 37s 1s/step - loss: 1.9299 - accuracy: 0.4730 - val_loss: 1.7448 - val_accuracy: 0.4911\n",
            "Epoch 2/10\n",
            "22/22 [==============================] - 25s 1s/step - loss: 1.7271 - accuracy: 0.4915 - val_loss: 1.7189 - val_accuracy: 0.4911\n",
            "Epoch 3/10\n",
            "22/22 [==============================] - 21s 973ms/step - loss: 1.6809 - accuracy: 0.4915 - val_loss: 1.6812 - val_accuracy: 0.4911\n",
            "Epoch 4/10\n",
            "22/22 [==============================] - 24s 1s/step - loss: 1.6122 - accuracy: 0.4930 - val_loss: 1.6494 - val_accuracy: 0.4911\n",
            "Epoch 5/10\n",
            "22/22 [==============================] - 22s 989ms/step - loss: 1.4667 - accuracy: 0.5122 - val_loss: 1.6584 - val_accuracy: 0.4793\n",
            "Epoch 6/10\n",
            "22/22 [==============================] - 23s 1s/step - loss: 1.2383 - accuracy: 0.5603 - val_loss: 1.6733 - val_accuracy: 0.4734\n",
            "Epoch 7/10\n",
            "22/22 [==============================] - 21s 981ms/step - loss: 1.1284 - accuracy: 0.5818 - val_loss: 1.8346 - val_accuracy: 0.4763\n",
            "Epoch 8/10\n",
            "22/22 [==============================] - 23s 1s/step - loss: 1.0832 - accuracy: 0.6092 - val_loss: 1.9781 - val_accuracy: 0.4911\n",
            "Epoch 9/10\n",
            "22/22 [==============================] - 20s 923ms/step - loss: 1.0621 - accuracy: 0.5877 - val_loss: 1.8051 - val_accuracy: 0.4349\n",
            "Epoch 10/10\n",
            "22/22 [==============================] - 22s 981ms/step - loss: 1.0999 - accuracy: 0.6351 - val_loss: 1.7836 - val_accuracy: 0.4704\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Layer lstm_2 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm_2 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm_2 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test accuracy for fold 1: 44.14%\n",
            "\n",
            "Fold 2\n",
            "Epoch 1/10\n",
            "22/22 [==============================] - 33s 1s/step - loss: 1.9523 - accuracy: 0.4471 - val_loss: 1.7487 - val_accuracy: 0.4911\n",
            "Epoch 2/10\n",
            "22/22 [==============================] - 24s 1s/step - loss: 1.7287 - accuracy: 0.4915 - val_loss: 1.7110 - val_accuracy: 0.4911\n",
            "Epoch 3/10\n",
            "22/22 [==============================] - 21s 976ms/step - loss: 1.6859 - accuracy: 0.4915 - val_loss: 1.7101 - val_accuracy: 0.4911\n",
            "Epoch 4/10\n",
            "22/22 [==============================] - 23s 1s/step - loss: 1.6344 - accuracy: 0.4915 - val_loss: 1.6494 - val_accuracy: 0.4911\n",
            "Epoch 5/10\n",
            "22/22 [==============================] - 21s 982ms/step - loss: 1.4782 - accuracy: 0.5174 - val_loss: 1.6364 - val_accuracy: 0.5178\n",
            "Epoch 6/10\n",
            "22/22 [==============================] - 23s 1s/step - loss: 1.2817 - accuracy: 0.5522 - val_loss: 1.6682 - val_accuracy: 0.5089\n",
            "Epoch 7/10\n",
            "22/22 [==============================] - 20s 927ms/step - loss: 1.1482 - accuracy: 0.5840 - val_loss: 1.8165 - val_accuracy: 0.4675\n",
            "Epoch 8/10\n",
            "22/22 [==============================] - 23s 1s/step - loss: 1.0754 - accuracy: 0.6047 - val_loss: 1.7945 - val_accuracy: 0.4615\n",
            "Epoch 9/10\n",
            "22/22 [==============================] - 20s 925ms/step - loss: 1.0311 - accuracy: 0.6447 - val_loss: 1.8347 - val_accuracy: 0.4438\n",
            "Epoch 10/10\n",
            "22/22 [==============================] - 23s 1s/step - loss: 0.9604 - accuracy: 0.6617 - val_loss: 1.9910 - val_accuracy: 0.4438\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Layer lstm_3 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm_3 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm_3 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test accuracy for fold 2: 42.90%\n",
            "\n",
            "Fold 3\n",
            "Epoch 1/10\n",
            "22/22 [==============================] - 31s 1s/step - loss: 1.9454 - accuracy: 0.4730 - val_loss: 1.7505 - val_accuracy: 0.4911\n",
            "Epoch 2/10\n",
            "22/22 [==============================] - 40s 2s/step - loss: 1.7388 - accuracy: 0.4915 - val_loss: 1.7189 - val_accuracy: 0.4911\n",
            "Epoch 3/10\n",
            "22/22 [==============================] - 24s 1s/step - loss: 1.6774 - accuracy: 0.4915 - val_loss: 1.6931 - val_accuracy: 0.4911\n",
            "Epoch 4/10\n",
            "22/22 [==============================] - 23s 1s/step - loss: 1.5860 - accuracy: 0.4922 - val_loss: 1.6537 - val_accuracy: 0.4941\n",
            "Epoch 5/10\n",
            "22/22 [==============================] - 22s 1000ms/step - loss: 1.3877 - accuracy: 0.5285 - val_loss: 1.7957 - val_accuracy: 0.4852\n",
            "Epoch 6/10\n",
            "22/22 [==============================] - 24s 1s/step - loss: 1.3689 - accuracy: 0.5514 - val_loss: 1.6744 - val_accuracy: 0.4941\n",
            "Epoch 7/10\n",
            "22/22 [==============================] - 23s 1s/step - loss: 1.2151 - accuracy: 0.5596 - val_loss: 1.7436 - val_accuracy: 0.4941\n",
            "Epoch 8/10\n",
            "22/22 [==============================] - 24s 1s/step - loss: 1.1020 - accuracy: 0.5966 - val_loss: 1.9159 - val_accuracy: 0.4763\n",
            "Epoch 9/10\n",
            "22/22 [==============================] - 21s 965ms/step - loss: 1.0407 - accuracy: 0.5966 - val_loss: 2.0291 - val_accuracy: 0.4704\n",
            "Epoch 10/10\n",
            "22/22 [==============================] - 22s 998ms/step - loss: 0.9939 - accuracy: 0.6528 - val_loss: 2.0535 - val_accuracy: 0.4467\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Layer lstm_4 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm_4 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm_4 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test accuracy for fold 3: 44.28%\n",
            "\n",
            "Fold 4\n",
            "Epoch 1/10\n",
            "22/22 [==============================] - 30s 1s/step - loss: 1.9461 - accuracy: 0.4700 - val_loss: 1.7553 - val_accuracy: 0.4911\n",
            "Epoch 2/10\n",
            "22/22 [==============================] - 24s 1s/step - loss: 1.7277 - accuracy: 0.4915 - val_loss: 1.7297 - val_accuracy: 0.4911\n",
            "Epoch 3/10\n",
            "22/22 [==============================] - 22s 1s/step - loss: 1.6883 - accuracy: 0.4915 - val_loss: 1.7133 - val_accuracy: 0.4911\n",
            "Epoch 4/10\n",
            "22/22 [==============================] - 24s 1s/step - loss: 1.5939 - accuracy: 0.4944 - val_loss: 1.6922 - val_accuracy: 0.5000\n",
            "Epoch 5/10\n",
            "22/22 [==============================] - 21s 972ms/step - loss: 1.4051 - accuracy: 0.5381 - val_loss: 1.7518 - val_accuracy: 0.4497\n",
            "Epoch 6/10\n",
            "22/22 [==============================] - 23s 1s/step - loss: 1.2027 - accuracy: 0.5581 - val_loss: 1.8139 - val_accuracy: 0.4734\n",
            "Epoch 7/10\n",
            "22/22 [==============================] - 21s 976ms/step - loss: 1.1200 - accuracy: 0.5914 - val_loss: 1.9078 - val_accuracy: 0.4260\n",
            "Epoch 8/10\n",
            "22/22 [==============================] - 23s 1s/step - loss: 1.0644 - accuracy: 0.6203 - val_loss: 2.4095 - val_accuracy: 0.5000\n",
            "Epoch 9/10\n",
            "22/22 [==============================] - 20s 931ms/step - loss: 1.0266 - accuracy: 0.6380 - val_loss: 1.9804 - val_accuracy: 0.4379\n",
            "Epoch 10/10\n",
            "22/22 [==============================] - 23s 1s/step - loss: 0.9535 - accuracy: 0.6899 - val_loss: 2.2385 - val_accuracy: 0.4438\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Layer lstm_5 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm_5 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm_5 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test accuracy for fold 4: 45.52%\n",
            "\n",
            "Fold 5\n",
            "Epoch 1/10\n",
            "22/22 [==============================] - 30s 1s/step - loss: 1.9516 - accuracy: 0.4712 - val_loss: 1.7388 - val_accuracy: 0.4926\n",
            "Epoch 2/10\n",
            "22/22 [==============================] - 22s 988ms/step - loss: 1.7339 - accuracy: 0.4911 - val_loss: 1.7098 - val_accuracy: 0.4926\n",
            "Epoch 3/10\n",
            "22/22 [==============================] - 24s 1s/step - loss: 1.6764 - accuracy: 0.4911 - val_loss: 1.6776 - val_accuracy: 0.4926\n",
            "Epoch 4/10\n",
            "22/22 [==============================] - 21s 983ms/step - loss: 1.5889 - accuracy: 0.4919 - val_loss: 1.6287 - val_accuracy: 0.4926\n",
            "Epoch 5/10\n",
            "22/22 [==============================] - 23s 1s/step - loss: 1.3642 - accuracy: 0.5237 - val_loss: 1.8145 - val_accuracy: 0.4243\n",
            "Epoch 6/10\n",
            "22/22 [==============================] - 22s 1s/step - loss: 1.2659 - accuracy: 0.5629 - val_loss: 1.6328 - val_accuracy: 0.5074\n",
            "Epoch 7/10\n",
            "22/22 [==============================] - 22s 963ms/step - loss: 1.1278 - accuracy: 0.5947 - val_loss: 1.6976 - val_accuracy: 0.4777\n",
            "Epoch 8/10\n",
            "22/22 [==============================] - 22s 1s/step - loss: 1.0963 - accuracy: 0.5902 - val_loss: 1.7190 - val_accuracy: 0.4896\n",
            "Epoch 9/10\n",
            "22/22 [==============================] - 21s 933ms/step - loss: 1.0546 - accuracy: 0.6087 - val_loss: 1.7534 - val_accuracy: 0.4599\n",
            "Epoch 10/10\n",
            "22/22 [==============================] - 20s 930ms/step - loss: 1.0106 - accuracy: 0.6516 - val_loss: 1.8121 - val_accuracy: 0.4570\n",
            "Test accuracy for fold 5: 40.83%\n",
            "\n"
          ]
        }
      ],
      "source": [
        "\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "\n",
        "# Define the number of folds for k-fold cross-validation\n",
        "num_folds = 5\n",
        "\n",
        "# Define the stratified k-fold cross-validator\n",
        "kfold = StratifiedKFold(n_splits=num_folds, shuffle=True, random_state=42)\n",
        "\n",
        "# Convert the labels to integers\n",
        "labels = np.argmax(y_train, axis=1)\n",
        "\n",
        "# Iterate over the folds\n",
        "for fold, (train_idx, val_idx) in enumerate(kfold.split(X_train, labels)):\n",
        "    print(f'Fold {fold+1}')\n",
        "    \n",
        "    # Define the model architecture\n",
        "    model = Sequential()\n",
        "    model.add(tf.keras.layers.Embedding(max_features, embedding_dim, input_length=max_len))\n",
        "    model.add(Bidirectional(LSTM(lstm_units, dropout=0.2, recurrent_dropout=0.2)))\n",
        "    model.add(Dense(num_labels, activation='softmax'))\n",
        "    \n",
        "    # Compile the model\n",
        "    optimizer = Adam(learning_rate=0.0005)\n",
        "    model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
        "    \n",
        "    # Extract the training and validation data for the current fold\n",
        "    X_train_fold = X_train[train_idx]\n",
        "    y_train_fold = y_train[train_idx]\n",
        "    X_val_fold = X_train[val_idx]\n",
        "    y_val_fold = y_train[val_idx]\n",
        "    \n",
        "    # Train the model for the current fold\n",
        "    model.fit(X_train_fold, y_train_fold, batch_size=batch_size, epochs=epochs, validation_data=(X_val_fold, y_val_fold), verbose=1)\n",
        "    \n",
        "    # Evaluate the model on the test data for the current fold\n",
        "    scores = model.evaluate(X_test, y_test, verbose=0)\n",
        "    print(f'Test accuracy for fold {fold+1}: {scores[1]*100:.2f}%\\n')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "tJeT4MXwKCSQ"
      },
      "outputs": [],
      "source": [
        "###tf.config.run_functions_eagerly(True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "id": "S6-EAgrRZsG_",
        "outputId": "50f5e8c8-b1f4-4981-f46d-51dcf8d6fa35"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nfrom keras import callbacks\\nearlystopping = callbacks.EarlyStopping(monitor=\"val_loss\",\\n\\t\\t\\t\\t\\t\\t\\t\\t\\t\\tmode=\"min\", patience=5,\\n\\t\\t\\t\\t\\t\\t\\t\\t\\t\\trestore_best_weights=True)\\n\\nhistory = model.fit(X_train, y_train, batch_size=128,\\n\\t\\t\\t\\t\\tepochs=25, validation_data=(X_val, y_val),\\n\\t\\t\\t\\t\\tcallbacks=[earlystopping])\\n\\t\\t\\t\\t\\t'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 35
        }
      ],
      "source": [
        "'''\n",
        "from keras import callbacks\n",
        "earlystopping = callbacks.EarlyStopping(monitor=\"val_loss\",\n",
        "\t\t\t\t\t\t\t\t\t\tmode=\"min\", patience=5,\n",
        "\t\t\t\t\t\t\t\t\t\trestore_best_weights=True)\n",
        "\n",
        "history = model.fit(X_train, y_train, batch_size=128,\n",
        "\t\t\t\t\tepochs=25, validation_data=(X_val, y_val),\n",
        "\t\t\t\t\tcallbacks=[earlystopping])\n",
        "\t\t\t\t\t'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DWqITn62w7Kl",
        "outputId": "7608cde2-bcd0-4e33-b74c-3a7eccaf3365"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "19/19 [==============================] - 1s 56ms/step\n"
          ]
        }
      ],
      "source": [
        "prediction= model.predict(X_val)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GXhF8RmTw7NS",
        "outputId": "ebcef18c-4d94-4a0f-f20c-2cffcbfafe81"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[1.19537540e-01 9.67921913e-02 9.53296721e-02 ... 5.46579100e-02\n",
            "  5.55274673e-02 1.83679715e-01]\n",
            " [1.22046247e-01 1.07525632e-01 1.06145270e-01 ... 5.84494323e-02\n",
            "  4.72834446e-02 1.85361236e-01]\n",
            " [9.01603028e-02 7.67467692e-02 9.27408487e-02 ... 6.09543286e-02\n",
            "  1.26168251e-01 1.69733003e-01]\n",
            " ...\n",
            " [1.30423449e-03 8.58630752e-04 2.01112847e-03 ... 8.15165229e-04\n",
            "  9.70877647e-01 6.88784011e-03]\n",
            " [2.43146508e-03 1.54244702e-03 2.94219214e-03 ... 9.67130822e-04\n",
            "  9.55156326e-01 1.08342962e-02]\n",
            " [1.20286785e-01 1.10976756e-01 1.11277737e-01 ... 1.38749763e-01\n",
            "  1.67297516e-02 1.24218941e-01]]\n"
          ]
        }
      ],
      "source": [
        "print(prediction)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "23btHiiZw7Pz"
      },
      "outputs": [],
      "source": [
        "Decode_prediction=np.argmax(prediction,axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "xUd4ZyMOw7SG"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "le = LabelEncoder()\n",
        "le.fit(training_df['label'])\n",
        "final_prediction=le.inverse_transform(Decode_prediction)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "Ago7NiYyShqV"
      },
      "outputs": [],
      "source": [
        "valid_df['prediction_values']=final_prediction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "WE9xdrBzS2Fi"
      },
      "outputs": [],
      "source": [
        "valid_df=valid_df.reindex(columns=['tagged_in_context','label','prediction_values'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "05Se7uMWU7jI",
        "outputId": "2e8e3c51-3e8c-48ab-9ca5-f065d57cebd3"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                     tagged_in_context  \\\n",
              "0    On average, between 300 and 600 infections are...   \n",
              "1    Mostly because <BOS> the country would not las...   \n",
              "2    Lyndon Johnson <BOS> gets Earl Warren and Sen....   \n",
              "3             <BOS> You <EOS> may opt out at anytime.    \n",
              "4    It must be exacted from him directly in order ...   \n",
              "..                                                 ...   \n",
              "575  NewsCatholic Church, <BOS> Family, Marriage <E...   \n",
              "576  Remember our saying, modern day fairy <BOS> ta...   \n",
              "577  Why <BOS> not <EOS> open up to Iran with massi...   \n",
              "578  <BOS> He also sang an Islamic State fight song...   \n",
              "579  We hear again, as we did incessantly from the ...   \n",
              "\n",
              "                         label          prediction_values  \n",
              "0               not_propaganda            loaded_language  \n",
              "1    causal_oversimplification                 repetition  \n",
              "2     appeal_to_fear_prejudice            loaded_language  \n",
              "3               not_propaganda             not_propaganda  \n",
              "4                   repetition      name_calling,labeling  \n",
              "..                         ...                        ...  \n",
              "575             not_propaganda             not_propaganda  \n",
              "576             not_propaganda             not_propaganda  \n",
              "577             not_propaganda             not_propaganda  \n",
              "578                flag_waving             not_propaganda  \n",
              "579  causal_oversimplification  exaggeration,minimisation  \n",
              "\n",
              "[580 rows x 3 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-83b3f23a-44cd-44d3-9d34-6bf43f205422\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>tagged_in_context</th>\n",
              "      <th>label</th>\n",
              "      <th>prediction_values</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>On average, between 300 and 600 infections are...</td>\n",
              "      <td>not_propaganda</td>\n",
              "      <td>loaded_language</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Mostly because &lt;BOS&gt; the country would not las...</td>\n",
              "      <td>causal_oversimplification</td>\n",
              "      <td>repetition</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Lyndon Johnson &lt;BOS&gt; gets Earl Warren and Sen....</td>\n",
              "      <td>appeal_to_fear_prejudice</td>\n",
              "      <td>loaded_language</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>&lt;BOS&gt; You &lt;EOS&gt; may opt out at anytime.</td>\n",
              "      <td>not_propaganda</td>\n",
              "      <td>not_propaganda</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>It must be exacted from him directly in order ...</td>\n",
              "      <td>repetition</td>\n",
              "      <td>name_calling,labeling</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>575</th>\n",
              "      <td>NewsCatholic Church, &lt;BOS&gt; Family, Marriage &lt;E...</td>\n",
              "      <td>not_propaganda</td>\n",
              "      <td>not_propaganda</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>576</th>\n",
              "      <td>Remember our saying, modern day fairy &lt;BOS&gt; ta...</td>\n",
              "      <td>not_propaganda</td>\n",
              "      <td>not_propaganda</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>577</th>\n",
              "      <td>Why &lt;BOS&gt; not &lt;EOS&gt; open up to Iran with massi...</td>\n",
              "      <td>not_propaganda</td>\n",
              "      <td>not_propaganda</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>578</th>\n",
              "      <td>&lt;BOS&gt; He also sang an Islamic State fight song...</td>\n",
              "      <td>flag_waving</td>\n",
              "      <td>not_propaganda</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>579</th>\n",
              "      <td>We hear again, as we did incessantly from the ...</td>\n",
              "      <td>causal_oversimplification</td>\n",
              "      <td>exaggeration,minimisation</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>580 rows × 3 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-83b3f23a-44cd-44d3-9d34-6bf43f205422')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-83b3f23a-44cd-44d3-9d34-6bf43f205422 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-83b3f23a-44cd-44d3-9d34-6bf43f205422');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ],
      "source": [
        "valid_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u0vLOmfXkEbQ",
        "outputId": "0414b920-af2b-4e6a-d08f-0257cf7278a5"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "8"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ],
      "source": [
        " valid_df['prediction_values'].nunique()"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "qJsb_iWvN6s5"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "a5f60b7a3780459e99a534165d22e238": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_2c03c7e3033446e6abdaa13e323db90a",
              "IPY_MODEL_a00813853f2b4fd694ddcd1a5c15d2d9",
              "IPY_MODEL_0b7f93d42d8e4fccb16ccb5a98273889"
            ],
            "layout": "IPY_MODEL_b0c0e216f1eb4ee7b9cb5c146bf9d607"
          }
        },
        "2c03c7e3033446e6abdaa13e323db90a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_45aeacf98e1940239a5356df3b9007f3",
            "placeholder": "​",
            "style": "IPY_MODEL_f6aa4af6698c46a2b605fcee01f448c6",
            "value": "Downloading pytorch_model.bin: 100%"
          }
        },
        "a00813853f2b4fd694ddcd1a5c15d2d9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d3de20112936440cac0d14afa114073a",
            "max": 440473133,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_7a47570bf38642b38883684635705413",
            "value": 440473133
          }
        },
        "0b7f93d42d8e4fccb16ccb5a98273889": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5301181a22a640258bf85d09403006de",
            "placeholder": "​",
            "style": "IPY_MODEL_5b019e459ad046dc881c8032ff2a8f04",
            "value": " 440M/440M [00:06&lt;00:00, 68.2MB/s]"
          }
        },
        "b0c0e216f1eb4ee7b9cb5c146bf9d607": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "45aeacf98e1940239a5356df3b9007f3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f6aa4af6698c46a2b605fcee01f448c6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d3de20112936440cac0d14afa114073a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7a47570bf38642b38883684635705413": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "5301181a22a640258bf85d09403006de": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5b019e459ad046dc881c8032ff2a8f04": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}